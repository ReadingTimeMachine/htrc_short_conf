{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3318403e",
   "metadata": {},
   "source": [
    "# Pull images to classify with MakeSense.ai\n",
    "\n",
    "Randomly pulled, tracked, for use with [MakeSense.ai](https://www.makesense.ai/) as a possible annotation interface.\n",
    "\n",
    "Steps are:\n",
    "1. Run the ocr_and_image_processing_batch.py file\n",
    "1. Run this file\n",
    "\n",
    "In your tmp storage (as defined in the config file) -- there will now be a MakeSense directory\n",
    " * go to makesense.ai and copy images into the upload box (in `<tmpfolder>/images`) and select Object Detection as your makesense.ai task\n",
    " * go to Actions -> Import Annotations and import labels and annotations with the documents in `<tmpfolder>/annotations` -- make sure to select \"multiple files\" (not a single COCO file) for the upload.\n",
    " * When finished annotating do Actions -> Export Annotations -> as *single* CSV file\n",
    " * Move this file to your `check_makesense` directory.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "42a85ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "68a7a2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PMC PubLayNet\n",
    "check_makesense = '/Users/jnaiman/Dropbox/wwt_image_extraction/FigureLocalization/BenchMarks/Annotations_htrc/MakeSenseAnnotations/'\n",
    "save_makesense = check_makesense\n",
    "ocr_results_dir = '/Users/jnaiman/Dropbox/wwt_image_extraction/FigureLocalization/BenchMarks/OCR_processing_htrc/'\n",
    "images_jpeg_dir = '/Users/jnaiman/Dropbox/wwt_image_extraction/FigureLocalization/BenchMarks/Pages_htrc/RandomSingleFromPDFIndexed/'\n",
    "check_json_dir = None\n",
    "\n",
    "# # defaults\n",
    "# ocr_results_dir = None\n",
    "# images_jpeg_dir = None\n",
    "# check_json_dir = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e692463f-bb95-4085-8532-697ed4ee58cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use prior weights to seed the boxes -- these come from the training\n",
    "binary_dirs = 'binaries_model12_tfrecordz/'\n",
    "weightsFileDir = config.save_weights_dir +'saved_weights/'+'20211218_model12tfz/'\n",
    "weightsFile = 'training_1model12_tfrec_model_l0.019131713.h5'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "afe74df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many you wanna grab?\n",
    "nRandom = 100\n",
    "\n",
    "# invert colors?\n",
    "invert_colors = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b1b13735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels for annotations:\n",
    "labels = ['figure', 'figure caption', 'table', 'math formula', 'sub fig caption', 'colorbar', 'NotSure', 'no label'] # no label is for nothing on the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0d500faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import post_processing_utils\n",
    "# from importlib import reload\n",
    "# reload(post_processing_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ab1c88a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "\n",
    "from annotation_utils import get_all_ocr_files, collect_ocr_process_results\n",
    "from mega_yolo_utils import build_predict\n",
    "from feature_generation_utils import generate_single_feature\n",
    "from post_processing_utils import get_ocr_results,get_image_process_boxes, \\\n",
    "    clean_merge_heurstic_captions, clean_overlapping_squares, clean_found_overlap_with_ocr, \\\n",
    "    clean_merge_squares, clean_big_captions, clean_match_fig_cap, expand_found_boxes_fig_cap, \\\n",
    "    expand_found_area_above_cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "dcc97912",
   "metadata": {},
   "outputs": [],
   "source": [
    "if images_jpeg_dir is None: images_jpeg_dir = config.images_jpeg_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "708ef1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save labels\n",
    "# save feature list\n",
    "with open(save_makesense +'saved_labels.pickle', 'wb') as ff:\n",
    "    pickle.dump([labels], ff)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "eca9db05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/jnaiman/Dropbox/wwt_image_extraction/FigureLocalization/BenchMarks/OCR_processing_htrc/full_ocr_newPDFs_TIFF_take5.pickle',\n",
       " '/Users/jnaiman/Dropbox/wwt_image_extraction/FigureLocalization/BenchMarks/OCR_processing_htrc/full_ocr_newPDFs_TIFF_take3.pickle',\n",
       " '/Users/jnaiman/Dropbox/wwt_image_extraction/FigureLocalization/BenchMarks/OCR_processing_htrc/full_ocr_newPDFs_TIFF_take1.pickle',\n",
       " '/Users/jnaiman/Dropbox/wwt_image_extraction/FigureLocalization/BenchMarks/OCR_processing_htrc/full_ocr_newPDFs_TIFF_take4.pickle',\n",
       " '/Users/jnaiman/Dropbox/wwt_image_extraction/FigureLocalization/BenchMarks/OCR_processing_htrc/full_ocr_newPDFs_TIFF_take2.pickle']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocrFiles = get_all_ocr_files(ocr_results_dir=ocr_results_dir)\n",
    "ocrFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5b53ac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import annotation_utils\n",
    "# reload(annotation_utils)\n",
    "# from annotation_utils import collect_ocr_process_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0a070de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retreiving OCR data, this can take a moment...\n",
      "##### OCR retrieval FILE: on 1 of 5  ##### \n",
      "--- OCR retrieval: on 0 of 50 ---\n",
      "##### OCR retrieval FILE: on 2 of 5  ##### \n",
      "--- OCR retrieval: on 0 of 20 ---\n",
      "##### OCR retrieval FILE: on 3 of 5  ##### \n",
      "--- OCR retrieval: on 0 of 29 ---\n",
      "##### OCR retrieval FILE: on 4 of 5  ##### \n",
      "--- OCR retrieval: on 0 of 25 ---\n",
      "##### OCR retrieval FILE: on 5 of 5  ##### \n",
      "--- OCR retrieval: on 0 of 20 ---\n"
     ]
    }
   ],
   "source": [
    "print('retreiving OCR data, this can take a moment...')\n",
    "ws1, paragraphs1, squares1, html1, rotations1,colorbars1 = collect_ocr_process_results(ocrFiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199c5b98-6719-4906-a580-6b9ff0971811",
   "metadata": {},
   "source": [
    "## Generally start here for same dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fae5d833",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t7/bwcvd_4177q4872gxghn7p9r0000gq/T/ipykernel_29062/2011718989.py:35: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfTmp = dfTmp.append(d)\n",
      "/var/folders/t7/bwcvd_4177q4872gxghn7p9r0000gq/T/ipykernel_29062/2011718989.py:35: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfTmp = dfTmp.append(d)\n",
      "/var/folders/t7/bwcvd_4177q4872gxghn7p9r0000gq/T/ipykernel_29062/2011718989.py:35: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfTmp = dfTmp.append(d)\n",
      "/var/folders/t7/bwcvd_4177q4872gxghn7p9r0000gq/T/ipykernel_29062/2011718989.py:35: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfTmp = dfTmp.append(d)\n",
      "/var/folders/t7/bwcvd_4177q4872gxghn7p9r0000gq/T/ipykernel_29062/2011718989.py:35: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfTmp = dfTmp.append(d)\n",
      "/var/folders/t7/bwcvd_4177q4872gxghn7p9r0000gq/T/ipykernel_29062/2011718989.py:35: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfTmp = dfTmp.append(d)\n",
      "/var/folders/t7/bwcvd_4177q4872gxghn7p9r0000gq/T/ipykernel_29062/2011718989.py:35: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfTmp = dfTmp.append(d)\n"
     ]
    }
   ],
   "source": [
    "# get all dones already\n",
    "\n",
    "# generate donesfile from list\n",
    "if type(check_makesense) != list:\n",
    "    lfiles = glob(check_makesense+'labels*csv')\n",
    "else:\n",
    "    lfiles = glob(check_makesense[0]+'labels*csv')\n",
    "    for c in check_makesense[1:]:\n",
    "        lfiles.extend(glob(c+'labels*csv'))\n",
    "\n",
    "l2 = glob(save_makesense+'labels*csv')\n",
    "lfiles.extend(l2)\n",
    "filenames = []; labelss = []; xmins = []; ymins=[]; xmaxs=[]; ymaxs=[]; widths=[]\n",
    "fnameSave = []; heights = []\n",
    "for il,l in enumerate(lfiles):\n",
    "    with open(l,'r') as ftrial:\n",
    "        text = ftrial.readline()\n",
    "        if 'label_name' in text: # have header, overwrite\n",
    "            d = pd.read_csv(l, \n",
    "                            names=['label','xmin','ymin','xmax','ymax', 'fname','x','y'],\n",
    "                           skiprows=1)\n",
    "        else: # no header\n",
    "            d = pd.read_csv(l, names=['label','xmin','ymin','xmax','ymax', 'fname','x','y'])\n",
    "\n",
    "    #d = pd.read_csv(l, names = ['label','xmin','ymin','xmax','ymax', 'fname','x','y'])\n",
    "    #d = d.drop_duplicates(subset='fname')\n",
    "    for idd, dd in enumerate(d['fname'].values):\n",
    "        fn = dd[:dd.rfind('.')+1]\n",
    "        if fn[-1] == '.': fn = fn[:-1]\n",
    "        filenames.append(fn)\n",
    "        fnameSave.append(dd)\n",
    "    if il == 0:\n",
    "        dfTmp = d.copy()\n",
    "    else:\n",
    "        dfTmp = dfTmp.append(d)\n",
    "# get unique\n",
    "fnameSave,uind = np.unique(fnameSave,return_index=True)\n",
    "# loop and grab\n",
    "for idd, dd in enumerate(fnameSave):\n",
    "    mask = dfTmp['fname'] == dd\n",
    "    labelss.append(dfTmp.loc[mask]['label'].values); xmins.append(dfTmp.loc[mask]['xmin'].values)\n",
    "    ymins.append(dfTmp.loc[mask]['ymin'].values); \n",
    "    # widths and heights!!\n",
    "    xmaxs.append(dfTmp.loc[mask]['xmax'].values+dfTmp.loc[mask]['xmin'].values); \n",
    "    ymaxs.append(dfTmp.loc[mask]['ymax'].values+dfTmp.loc[mask]['ymin'].values)\n",
    "    widths.append(dfTmp.loc[mask]['x'].values[0]); heights.append(dfTmp.loc[mask]['y'].values[0])\n",
    "dones = pd.DataFrame({'filename':np.array(filenames)[uind], 'labels':labelss, 'xmin':xmins, \n",
    "                      'ymin':ymins, 'xmax':xmaxs,'ymax':ymaxs, 'width':widths, 'height':heights})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4204bc27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>labels</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003_uc1-31210014680225-1666394091_p1</td>\n",
       "      <td>[no_label, no_label]</td>\n",
       "      <td>[2766, 2766]</td>\n",
       "      <td>[3223, 3223]</td>\n",
       "      <td>[2924, 2924]</td>\n",
       "      <td>[3407, 3407]</td>\n",
       "      <td>3161</td>\n",
       "      <td>3683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003_uc1-31210014680225-1666394091_p102</td>\n",
       "      <td>[table, table]</td>\n",
       "      <td>[256, 256]</td>\n",
       "      <td>[240, 240]</td>\n",
       "      <td>[2354, 2354]</td>\n",
       "      <td>[3278, 3278]</td>\n",
       "      <td>2652</td>\n",
       "      <td>3504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003_uc1-31210014680225-1666394091_p118</td>\n",
       "      <td>[table, table]</td>\n",
       "      <td>[266, 266]</td>\n",
       "      <td>[154, 154]</td>\n",
       "      <td>[2157, 2157]</td>\n",
       "      <td>[3192, 3192]</td>\n",
       "      <td>2727</td>\n",
       "      <td>3487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003_uc1-31210014680225-1666394091_p127</td>\n",
       "      <td>[table, table]</td>\n",
       "      <td>[349, 349]</td>\n",
       "      <td>[198, 198]</td>\n",
       "      <td>[2232, 2232]</td>\n",
       "      <td>[3298, 3298]</td>\n",
       "      <td>2719</td>\n",
       "      <td>3525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003_uc1-31210014680225-1666394091_p136</td>\n",
       "      <td>[table, table]</td>\n",
       "      <td>[243, 243]</td>\n",
       "      <td>[192, 192]</td>\n",
       "      <td>[1911, 1911]</td>\n",
       "      <td>[3228, 3228]</td>\n",
       "      <td>2619</td>\n",
       "      <td>3491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>uiug-30112101602172-1666102417_p3</td>\n",
       "      <td>[table, table]</td>\n",
       "      <td>[487, 487]</td>\n",
       "      <td>[9, 9]</td>\n",
       "      <td>[2326, 2326]</td>\n",
       "      <td>[3052, 3052]</td>\n",
       "      <td>2372</td>\n",
       "      <td>3262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>uiug-30112101602172-1666102417_p4</td>\n",
       "      <td>[no_label, no_label]</td>\n",
       "      <td>[2080, 2080]</td>\n",
       "      <td>[2851, 2851]</td>\n",
       "      <td>[2199, 2199]</td>\n",
       "      <td>[3014, 3014]</td>\n",
       "      <td>2377</td>\n",
       "      <td>3258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>uiug-30112101602172-1666102417_p5</td>\n",
       "      <td>[no_label, no_label]</td>\n",
       "      <td>[2106, 2106]</td>\n",
       "      <td>[2963, 2963]</td>\n",
       "      <td>[2286, 2286]</td>\n",
       "      <td>[3143, 3143]</td>\n",
       "      <td>2372</td>\n",
       "      <td>3258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>uiug-30112101602172-1666102417_p6</td>\n",
       "      <td>[no_label, no_label]</td>\n",
       "      <td>[2080, 2080]</td>\n",
       "      <td>[2854, 2854]</td>\n",
       "      <td>[2199, 2199]</td>\n",
       "      <td>[3017, 3017]</td>\n",
       "      <td>2377</td>\n",
       "      <td>3262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>uiug-30112101602172-1666102417_p7</td>\n",
       "      <td>[no_label, no_label]</td>\n",
       "      <td>[2145, 2145]</td>\n",
       "      <td>[2888, 2888]</td>\n",
       "      <td>[2300, 2300]</td>\n",
       "      <td>[3176, 3176]</td>\n",
       "      <td>2372</td>\n",
       "      <td>3271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   filename                labels  \\\n",
       "0     2003_uc1-31210014680225-1666394091_p1  [no_label, no_label]   \n",
       "1   2003_uc1-31210014680225-1666394091_p102        [table, table]   \n",
       "2   2003_uc1-31210014680225-1666394091_p118        [table, table]   \n",
       "3   2003_uc1-31210014680225-1666394091_p127        [table, table]   \n",
       "4   2003_uc1-31210014680225-1666394091_p136        [table, table]   \n",
       "..                                      ...                   ...   \n",
       "80        uiug-30112101602172-1666102417_p3        [table, table]   \n",
       "81        uiug-30112101602172-1666102417_p4  [no_label, no_label]   \n",
       "82        uiug-30112101602172-1666102417_p5  [no_label, no_label]   \n",
       "83        uiug-30112101602172-1666102417_p6  [no_label, no_label]   \n",
       "84        uiug-30112101602172-1666102417_p7  [no_label, no_label]   \n",
       "\n",
       "            xmin          ymin          xmax          ymax  width  height  \n",
       "0   [2766, 2766]  [3223, 3223]  [2924, 2924]  [3407, 3407]   3161    3683  \n",
       "1     [256, 256]    [240, 240]  [2354, 2354]  [3278, 3278]   2652    3504  \n",
       "2     [266, 266]    [154, 154]  [2157, 2157]  [3192, 3192]   2727    3487  \n",
       "3     [349, 349]    [198, 198]  [2232, 2232]  [3298, 3298]   2719    3525  \n",
       "4     [243, 243]    [192, 192]  [1911, 1911]  [3228, 3228]   2619    3491  \n",
       "..           ...           ...           ...           ...    ...     ...  \n",
       "80    [487, 487]        [9, 9]  [2326, 2326]  [3052, 3052]   2372    3262  \n",
       "81  [2080, 2080]  [2851, 2851]  [2199, 2199]  [3014, 3014]   2377    3258  \n",
       "82  [2106, 2106]  [2963, 2963]  [2286, 2286]  [3143, 3143]   2372    3258  \n",
       "83  [2080, 2080]  [2854, 2854]  [2199, 2199]  [3017, 3017]   2377    3262  \n",
       "84  [2145, 2145]  [2888, 2888]  [2300, 2300]  [3176, 3176]   2372    3271  \n",
       "\n",
       "[85 rows x 8 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6bca7cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85, 85)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donefiles = dones['filename'].values\n",
    "len(donefiles), len(np.unique(donefiles))\n",
    "# debug\n",
    "#donefiles = ['ofx163.1581.PMC5630905_p1.jpeg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4e467a48-abc0-4cae-9ddc-fb805676e18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already classified:\n",
      "figure 36.0\n",
      "figure caption 38.0\n",
      "table 56.0\n",
      "math formula 54.0\n",
      "sub fig caption 0.0\n",
      "colorbar 0.0\n",
      "NotSure 0.0\n",
      "no label 84.0\n"
     ]
    }
   ],
   "source": [
    "# count how many done per class\n",
    "labels_done_count = np.zeros(len(labels))\n",
    "for i in range(len(dones)):\n",
    "    for l in dones.iloc[i]['labels']:\n",
    "        indd = labels.index(l.replace('_',' '))\n",
    "        labels_done_count[indd] += 1\n",
    "print('Already classified:')\n",
    "for i in range(len(labels)):\n",
    "    print(labels[i], labels_done_count[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c7d9edae-0a81-4394-903d-5ec2532f1539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(donefiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "01707145-317e-4d95-ac2c-15b0b7ad3691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also, get list of error'd out scanbanks\n",
    "if check_json_dir is not None:\n",
    "    sbcheck = []\n",
    "    for i in range(len(donefiles)):\n",
    "        sbcheck.append(donefiles[i].split('_p')[0])\n",
    "    #sbcheck = np.unique(sbcheck).tolist()\n",
    "\n",
    "    # check for json file\n",
    "    #no_json = []\n",
    "    #for f in sbcheck:\n",
    "    #    f+'/'+pdfbase+'deepfigures-results.json'\n",
    "    donefiles = donefiles.tolist()\n",
    "    for f in sbcheck:\n",
    "        fc = check_json_dir + f\n",
    "        ff = glob(fc+'/*')[0]\n",
    "        if not os.path.isfile(ff + '/' + f + 'deepfigures-results.json'):\n",
    "            donefiles.append(f)\n",
    "            #print('yes')\n",
    "    donefiles = np.unique(donefiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8ca28144-e36f-4e59-8b5c-6125cff7637d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(donefiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "341015a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "ws, paragraphs, squares, html, rotations,colorbars = [],[],[],[],[],[]\n",
    "for w,p,s,h,r,c in zip(ws1,paragraphs1, squares1, html1, rotations1,colorbars1):\n",
    "    if w.split('.jpeg')[0] not in donefiles:\n",
    "        ws.append(w); paragraphs.append(p);squares.append(s)\n",
    "        html.append(h); rotations.append(r); colorbars.append(c)\n",
    "df = pd.DataFrame({'ws':ws, 'paragraphs':paragraphs, 'squares':squares, \n",
    "                   'hocr':html, 'rotation':rotations, 'colorbars':colorbars})#, 'pdfwords':pdfwords})\n",
    "df = df.drop_duplicates(subset='ws')\n",
    "df = df.set_index('ws')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "033f331c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you have 50 pages that you can pull from\n"
     ]
    }
   ],
   "source": [
    "print('you have', len(df), 'pages that you can pull from')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b57975a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if nRandom < len(ws):\n",
    "    # grab randomly\n",
    "    ind = np.random.choice(range(len(df)),nRandom,replace=False)\n",
    "    #ws = np.array(ws)[ind]\n",
    "else:\n",
    "    #ws = np.array(ws)\n",
    "    ind = np.arange(0,len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "26f8cb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfout = df.iloc[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "bd567e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>squares</th>\n",
       "      <th>hocr</th>\n",
       "      <th>rotation</th>\n",
       "      <th>colorbars</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ws</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>osu-32435023323769-1666273876_p164.jpeg</th>\n",
       "      <td>[(485, 186, 1053, 41), (485, 186, 1053, 41), (...</td>\n",
       "      <td>[[[453, 303], [1962, 303], [1962, 1761], [453,...</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\\n&lt;!DOCT...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989_uc1-32106020677263-1666572876_p96.jpeg</th>\n",
       "      <td>[(359, 263, 1814, 44), (359, 263, 1814, 44), (...</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\\n&lt;!DOCT...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>osu-32435023323769-1666273876_p148.jpeg</th>\n",
       "      <td>[(365, 246, 59, 31), (1178, 252, 339, 31), (11...</td>\n",
       "      <td>[[[884, 2000], [1871, 2000], [1871, 2739], [88...</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\\n&lt;!DOCT...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[[[1655, 2078], [1655, 2167], [1667, 2167], [1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989_uc1-32106020677263-1666572876_p137.jpeg</th>\n",
       "      <td>[(286, 273, 1886, 45), (286, 273, 1886, 45), (...</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\\n&lt;!DOCT...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989_uc1-32106020677263-1666572876_p78.jpeg</th>\n",
       "      <td>[(2199, 377, 3, 22), (2197, 1417, 4, 19), (217...</td>\n",
       "      <td>[[[638, 1653], [1998, 1653], [1998, 3014], [63...</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\\n&lt;!DOCT...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                     paragraphs  \\\n",
       "ws                                                                                                \n",
       "osu-32435023323769-1666273876_p164.jpeg       [(485, 186, 1053, 41), (485, 186, 1053, 41), (...   \n",
       "1989_uc1-32106020677263-1666572876_p96.jpeg   [(359, 263, 1814, 44), (359, 263, 1814, 44), (...   \n",
       "osu-32435023323769-1666273876_p148.jpeg       [(365, 246, 59, 31), (1178, 252, 339, 31), (11...   \n",
       "1989_uc1-32106020677263-1666572876_p137.jpeg  [(286, 273, 1886, 45), (286, 273, 1886, 45), (...   \n",
       "1989_uc1-32106020677263-1666572876_p78.jpeg   [(2199, 377, 3, 22), (2197, 1417, 4, 19), (217...   \n",
       "\n",
       "                                                                                        squares  \\\n",
       "ws                                                                                                \n",
       "osu-32435023323769-1666273876_p164.jpeg       [[[453, 303], [1962, 303], [1962, 1761], [453,...   \n",
       "1989_uc1-32106020677263-1666572876_p96.jpeg                                                  []   \n",
       "osu-32435023323769-1666273876_p148.jpeg       [[[884, 2000], [1871, 2000], [1871, 2739], [88...   \n",
       "1989_uc1-32106020677263-1666572876_p137.jpeg                                                 []   \n",
       "1989_uc1-32106020677263-1666572876_p78.jpeg   [[[638, 1653], [1998, 1653], [1998, 3014], [63...   \n",
       "\n",
       "                                                                                           hocr  \\\n",
       "ws                                                                                                \n",
       "osu-32435023323769-1666273876_p164.jpeg       <?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<!DOCT...   \n",
       "1989_uc1-32106020677263-1666572876_p96.jpeg   <?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<!DOCT...   \n",
       "osu-32435023323769-1666273876_p148.jpeg       <?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<!DOCT...   \n",
       "1989_uc1-32106020677263-1666572876_p137.jpeg  <?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<!DOCT...   \n",
       "1989_uc1-32106020677263-1666572876_p78.jpeg   <?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<!DOCT...   \n",
       "\n",
       "                                                                                       rotation  \\\n",
       "ws                                                                                                \n",
       "osu-32435023323769-1666273876_p164.jpeg       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1989_uc1-32106020677263-1666572876_p96.jpeg   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "osu-32435023323769-1666273876_p148.jpeg       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1989_uc1-32106020677263-1666572876_p137.jpeg  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1989_uc1-32106020677263-1666572876_p78.jpeg   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                                                      colorbars  \n",
       "ws                                                                                               \n",
       "osu-32435023323769-1666273876_p164.jpeg                                                      []  \n",
       "1989_uc1-32106020677263-1666572876_p96.jpeg                                                  []  \n",
       "osu-32435023323769-1666273876_p148.jpeg       [[[1655, 2078], [1655, 2167], [1667, 2167], [1...  \n",
       "1989_uc1-32106020677263-1666572876_p137.jpeg                                                 []  \n",
       "1989_uc1-32106020677263-1666572876_p78.jpeg                                                  []  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfout.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e8f4cc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ws = dfout.index\n",
    "# ws\n",
    "#dfout.index.values.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "73937ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save label file for annotations\n",
    "storeTmps = config.tmp_storage_dir + 'MakeSense/'\n",
    "if not os.path.exists(storeTmps):\n",
    "    os.mkdir(storeTmps)\n",
    "# remove, remake\n",
    "shutil.rmtree(storeTmps)\n",
    "os.mkdir(storeTmps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7f4450",
   "metadata": {},
   "source": [
    "Copy over random images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c3dc21fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start on empty\n",
    "if not os.path.exists(storeTmps+'images/'):\n",
    "    os.makedirs(storeTmps+'images/')\n",
    "# delete and remake\n",
    "shutil.rmtree(storeTmps+'images/')\n",
    "os.makedirs(storeTmps+'images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0018eb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move files\n",
    "imgSizes = []; imgSizesOrig = []\n",
    "for iw,w in enumerate(dfout.index.values.astype('str')):\n",
    "    #print(w)\n",
    "    w = images_jpeg_dir + w\n",
    "    if not invert_colors:\n",
    "        shutil.copyfile(w, storeTmps+'images/'+ w.split('/')[-1])\n",
    "        imgSizes.append(Image.open(w).convert('RGB').size)\n",
    "    else: # invert B/W\n",
    "        print('not implemented!!')\n",
    "        import sys; sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0cf92189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write label file\n",
    "with open(storeTmps + 'labels.txt','w') as f:\n",
    "    for l in labels:\n",
    "        f.write(l.replace(' ', '_') + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e807c8b",
   "metadata": {},
   "source": [
    "For annotations, try to predict with our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "343b9e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model to run on pages\n",
    "# read in anchors\n",
    "saveFileAnchors = weightsFileDir + 'anchors.pickle'\n",
    "with open(saveFileAnchors, 'rb') as f:\n",
    "    anchors = pickle.load(f) \n",
    "    anchors = anchors.astype('float32')\n",
    "\n",
    "    \n",
    "feature_dir = config.save_binary_dir + binary_dirs\n",
    "# how many features\n",
    "with open(feature_dir +'feature_list.pickle', 'rb') as ff:\n",
    "    feature_list = pickle.load(ff)[0]\n",
    "# HACK\n",
    "#feature_list = ['grayscale','fontsize','x_ascenders','x_decenders', 'word confidences', \n",
    "#                'fraction of numbers in a word','fraction of letters in a word','punctuation', \n",
    "#                'text angles','Spacy POS']\n",
    "\n",
    "n_features = len(feature_list)\n",
    "\n",
    "# labels file for originally trained\n",
    "LABELS=pd.read_csv(feature_dir + 'LABELS.csv',names=['labels'])['labels'].values.astype('str')\n",
    "CLASS = len(LABELS)\n",
    "\n",
    "# build the model\n",
    "weightsFileDownload = weightsFileDir + weightsFile\n",
    "anchorsFile = weightsFileDir + 'anchors.pickle'  # should this be changed....\n",
    "\n",
    "model = build_predict(weightsFileDownload, anchorsFile, \n",
    "                    feature_dir,LABELS,version=config.version, \n",
    "                      debug=False,n_features=n_features)\n",
    "model.load_weights(weightsFileDownload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "17a4be46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imgSizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "84953395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload(post_processing_utils)\n",
    "# from post_processing_utils import get_ocr_results,get_image_process_boxes, \\\n",
    "#     clean_merge_heurstic_captions, clean_overlapping_squares, clean_found_overlap_with_ocr, \\\n",
    "#     clean_merge_squares, clean_big_captions, clean_match_fig_cap, expand_found_boxes_fig_cap, \\\n",
    "#     expand_found_area_above_cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b07ed8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# # for tfrecrords, get datasets\n",
    "# test_list = glob(feature_dir + 'test_*tfrecords')\n",
    "\n",
    "# #if not use_training:\n",
    "# test_raw_data = tf.data.TFRecordDataset(filenames=test_list, \n",
    "#                                          compression_type='GZIP', \n",
    "#                                          buffer_size=None, \n",
    "#                                         num_parallel_reads=tf.data.AUTOTUNE)\n",
    "# Create a dictionary describing the features.\n",
    "image_feature_description = {\n",
    "    'nbox': tf.io.FixedLenFeature([], tf.float32),\n",
    "    'nfeatures': tf.io.FixedLenFeature([], tf.float32),\n",
    "    'boxes': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image_name': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "def _parse_image_function_test(example_proto,anchors,CLASS):\n",
    "    image_features = tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "    # parse the data\n",
    "    nboxes = image_features['nbox']\n",
    "    nfeatures = image_features['nfeatures']\n",
    "    images_raw = image_features['image_raw']\n",
    "    image = tf.io.decode_raw(images_raw,tf.float32)\n",
    "    image = tf.reshape(image,[config.IMAGE_H,config.IMAGE_W,nfeatures])\n",
    "    img_name = tf.cast(image_features['image_name'],tf.string)\n",
    "    return image,img_name\n",
    "\n",
    "# test_dataset = test_raw_data.map(lambda example_proto:_parse_image_function_test(example_proto,\n",
    "#                                                                              anchors,CLASS))\n",
    "\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    " \n",
    "# Create a dictionary with features that may be relevant.\n",
    "def image_example(image, boxes, img_name):\n",
    "    #image_shape = tf.io.decode_jpeg(image_string).shape\n",
    "    image_string = image.astype('float32')/255.0\n",
    "    image_string = image.reshape(image.shape[0]*image.shape[1]*image.shape[2])\n",
    "\n",
    "    nfeatures = image.shape[2]\n",
    "    nboxes = boxes.shape[0]\n",
    "    if nboxes>0:\n",
    "        boxout = boxes.reshape(boxes.shape[0]*boxes.shape[1])\n",
    "    else:\n",
    "        boxout = np.array([])\n",
    "\n",
    "    feature = {\n",
    "      'nbox': _float_feature(np.float32(nboxes)),\n",
    "      'nfeatures': _float_feature(np.float32(nfeatures)),\n",
    "      'boxes': _bytes_feature(boxout.astype('float32').tobytes()),\n",
    "      'image_raw': _bytes_feature(image_string.astype('float32').tobytes()),\n",
    "      'image_name': _bytes_feature(img_name.encode('utf-8')),\n",
    "    }\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))      \n",
    "\n",
    "compress = 'GZIP'\n",
    "tf_record_options = tf.io.TFRecordOptions(compression_type = compress) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "806362d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make file into tf record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75eef42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on 1 of 50\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 468ms/step\n",
      "1/1 [==============================] - 0s 490ms/step\n",
      "1/1 [==============================] - 1s 505ms/step\n",
      "1/1 [==============================] - 1s 534ms/step\n",
      "1/1 [==============================] - 0s 459ms/step\n",
      "1/1 [==============================] - 0s 467ms/step\n",
      "1/1 [==============================] - 0s 464ms/step\n",
      "1/1 [==============================] - 0s 472ms/step\n",
      "1/1 [==============================] - 0s 458ms/step\n",
      "1/1 [==============================] - 0s 476ms/step\n",
      "1/1 [==============================] - 0s 474ms/step\n",
      "1/1 [==============================] - 1s 541ms/step\n",
      "1/1 [==============================] - 0s 464ms/step\n",
      "1/1 [==============================] - 0s 483ms/step\n",
      "1989_uc1-32106020677263-1666572876_p221.jpeg something has happened with rotation -- page says angle = 180 words say angle = 0.0\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(storeTmps+'annotations/'):\n",
    "    os.makedirs(storeTmps+'annotations/')\n",
    "# delete and remake\n",
    "shutil.rmtree(storeTmps+'annotations/')\n",
    "os.makedirs(storeTmps+'annotations/')\n",
    "\n",
    "# save tmp binaries for this\n",
    "if not os.path.exists(storeTmps+'binaries/'):\n",
    "    os.makedirs(storeTmps+'binaries/')\n",
    "# delete and remake\n",
    "shutil.rmtree(storeTmps+'binaries/')\n",
    "os.makedirs(storeTmps+'binaries/')\n",
    "\n",
    "# just for counting\n",
    "maxboxes = 50 # I think this is actually a place holder...\n",
    "\n",
    "boxesout,labelsout = [],[]\n",
    "\n",
    "#for i in range(len(dfout)):\n",
    "#i = 6 #4\n",
    "#i=0\n",
    "#if True:\n",
    "#icount = 0\n",
    "#for image,images_name in test_dataset:\n",
    "    #imgs_name = images_name.numpy().decode('utf-8')\n",
    "for i in range(len(dfout)):\n",
    "    \n",
    "    if i%25 == 0: print('on', i+1, 'of', len(dfout))\n",
    "\n",
    "    dfsingle = dfout.iloc[i]\n",
    "    # if we've made it this far, let's generate features\n",
    "    img_name, font = generate_single_feature(dfsingle, LABELS, maxboxes, \n",
    "                                           feature_list = feature_list, \n",
    "                                           binary_dir = storeTmps+'binaries/',\n",
    "                                                images_jpeg_dir = images_jpeg_dir,\n",
    "                                                astype='npz', \n",
    "                                                 npzcompressed=True) \n",
    "    \n",
    "    image_np = np.load(img_name)['arr_0']\n",
    "    fakebox = np.random.random([20,5])\n",
    "    tf_example = image_example(image_np,fakebox,img_name)\n",
    "    # write temp\n",
    "    record_file = storeTmps+'binaries/tmpfile'\n",
    "    with tf.io.TFRecordWriter(record_file, options=tf_record_options) as writer:\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "        \n",
    "    test_raw_data = tf.data.TFRecordDataset(filenames=record_file, \n",
    "                                             compression_type='GZIP', \n",
    "                                             buffer_size=None, \n",
    "                                            num_parallel_reads=tf.data.AUTOTUNE)\n",
    "    test_dataset = test_raw_data.map(lambda example_proto:_parse_image_function_test(example_proto,\n",
    "                                                                                 anchors,CLASS))\n",
    "\n",
    "    for image,images_name in test_dataset:\n",
    "        imgs_name = images_name.numpy().decode('utf-8')\n",
    "    \n",
    "        # predict squares in 2 ways\n",
    "        # 1. MEGA YOLO\n",
    "        #image_np = np.load(img_name)['arr_0']\n",
    "        #image_np = image_np.astype(np.float32) / 255.0 \n",
    "        # backtorgb,image_np,rotatedImage,rotatedAngleOCR,bbox_hocr,\\\n",
    "        #   bboxes_words,bbsq,cbsq, rotation,bbox_par = get_ocr_results(img_name, None,dfout.iloc[[i]],\n",
    "        #                                                              image_np=image_np,\n",
    "        #                                                              width=imgSizes[i][0], \n",
    "        #                                                              height=imgSizes[i][1],\n",
    "        #                                                              images_jpeg_dir=images_jpeg_dir)\n",
    "        backtorgb,image_np,rotatedImage,rotatedAngleOCR,bbox_hocr,\\\n",
    "          bboxes_words,bbsq,cbsq, rotation,bbox_par = get_ocr_results(img_name, None,dfout.iloc[[i]],\n",
    "                                                                     image_np=image.numpy(),\n",
    "                                                                     width=imgSizes[i][0], \n",
    "                                                                     height=imgSizes[i][1],\n",
    "                                                                     images_jpeg_dir=images_jpeg_dir)\n",
    "\n",
    "        boxesh, scoresh, labelsh = model.predict(image_np[np.newaxis, ...])\n",
    "        #import sys; sys.exit()\n",
    "        boxes1, scores1, labels1 = np.squeeze(boxesh, 0), \\\n",
    "          np.squeeze(scoresh, 0), np.squeeze(labelsh, 0)\n",
    "        # only non -1 ones\n",
    "        boxes1 = boxes1[labels1>-1]\n",
    "        scores1 = scores1[labels1>-1]\n",
    "        labels1 = labels1[labels1>-1]    \n",
    "\n",
    "        # # post process the thing\n",
    "        # # get OCR results and parse them, open image for image processing\n",
    "        # image = \n",
    "\n",
    "\n",
    "        # get figures and captions from image processing\n",
    "        captionText_figcap, bbox_figcap_pars = get_image_process_boxes(backtorgb, \n",
    "                                                                       bbox_hocr, \n",
    "                                                                       rotatedImage)\n",
    "        # clean overlapping squares\n",
    "        # if squares are majorly overlapping, take the one with the highest score\n",
    "        sboxes_cleaned, slabels_cleaned, sscores_cleaned = clean_overlapping_squares(boxes1,\n",
    "                                                                                     scores1,\n",
    "                                                                                     labels1,\n",
    "                                                                                     img_name)\n",
    "        # combine figure caption boxes with heuristically found ones\n",
    "        # -- often the heurstically found boxes are more accurate, especially \n",
    "        # in the vertical direction\n",
    "        boxes_heur, labels_heur, scores_heur,\\\n",
    "          ibbOverlap, boxes_heur_tf = clean_merge_heurstic_captions(sboxes_cleaned, \n",
    "                                                     slabels_cleaned, \n",
    "                                                     sscores_cleaned, \n",
    "                                                bbox_figcap_pars, LABELS,None,\n",
    "                                                    width=imgSizes[i][0], \n",
    "                                                    height=imgSizes[i][1])\n",
    "        # NO PDF\n",
    "\n",
    "        # other way -- w/o adding more heursitic caps:\n",
    "        boxes_par_found, labels_par_found, \\\n",
    "          scores_par_found = clean_found_overlap_with_ocr(boxes_heur, labels_heur, \n",
    "                                                    scores_heur,bboxes_words,\n",
    "                                                          bbox_par,rotation,\n",
    "                                                          LABELS, None, boxes_heur_tf,\n",
    "                                                          width=imgSizes[i][0], \n",
    "                                                    height=imgSizes[i][1])\n",
    "\n",
    "        # if figure boxes are smaller than image-processing found boxes, merge them; \n",
    "        # also, do with colorbars as well if requested\n",
    "        boxes_sq1, labels_sq1, scores_sq1, bbsq = clean_merge_squares(bbsq, cbsq,\n",
    "                                                                boxes_par_found, \n",
    "                                                                labels_par_found, \n",
    "                                                                scores_par_found, \n",
    "                                                                LABELS, None, \n",
    "                                                                      width=imgSizes[i][0], \n",
    "                                                                      height=imgSizes[i][1])\n",
    "\n",
    "        # if there are any huge captions -- like 75% of the area of the page or more\n",
    "        #. these are wrong, so drop them\n",
    "        boxes_sq2, labels_sq2, scores_sq2 = clean_big_captions(boxes_sq1,\n",
    "                                                            labels_sq1,\n",
    "                                                            scores_sq1, \n",
    "                                                            LABELS)\n",
    "            \n",
    "        # sometimes captions are slightly overlapping with figures -- split the \n",
    "        # difference between those where they touch on the \"bottom\"\n",
    "        # Default to captions found with mega yolo, if there is a figure but \n",
    "        #. no caption found, then see if there is a heuristically found caption\n",
    "        boxes_sq3, labels_sq3, scores_sq3 = clean_match_fig_cap(boxes_sq2,\n",
    "                                                                 labels_sq2,\n",
    "                                                             scores_sq2, bbsq,\n",
    "                                                             LABELS.tolist(), \n",
    "                                                             rotatedImage, \n",
    "                                                             rotatedAngleOCR,\n",
    "                                                             None, \n",
    "                                                            width=imgSizes[i][0], \n",
    "                                                            height=imgSizes[i][1])\n",
    "        \n",
    "        # again for found boxes?  I feel like maybe not the one above?\n",
    "        boxes_sq4, labels_sq4, scores_sq4 = expand_found_boxes_fig_cap(boxes_sq3, \n",
    "                                                                    labels_sq3, \n",
    "                                                                    scores_sq3,\n",
    "                                                                       bbsq,\n",
    "                                                                    rotatedImage, \n",
    "                                                                    LABELS.tolist(), None, \n",
    "                                                            width=imgSizes[i][0], \n",
    "                                                            height=imgSizes[i][1])\n",
    "        \n",
    "        # same for found\n",
    "        boxes_sq5, labels_sq5, scores_sq5 = expand_found_area_above_cap(boxes_sq4, \n",
    "                                                                        labels_sq4, \n",
    "                                                                        scores_sq4, \n",
    "                                                                        bbsq,\n",
    "                                                                        rotatedImage, \n",
    "                                                                        LABELS.tolist(), None, \n",
    "                                                            width=imgSizes[i][0], \n",
    "                                                            height=imgSizes[i][1])\n",
    "        \n",
    "        # save it!\n",
    "        #boxesout.append(boxes_sq5); labelsout.append(labels_sq5)\n",
    "        \n",
    "    fn = imgs_name\n",
    "        \n",
    "    # write this out!\n",
    "    if os.path.exists(fn): \n",
    "        with open(storeTmps+'annotations/'+ fn.split('/')[-1].split('.npz')[0] + '.txt','w') as fsave:\n",
    "            for fb,ll in zip(boxes_sq5,labels_sq5):\n",
    "                xmin = fb[0]/config.IMAGE_W#*img.shape[1]\n",
    "                xmax = fb[2]/config.IMAGE_W#*img.shape[1]\n",
    "                ymin = fb[1]/config.IMAGE_H#*img.shape[0]\n",
    "                ymax = fb[3]/config.IMAGE_H#*img.shape[0]\n",
    "\n",
    "                #xmin = bb[0]*xfrac; ymin = bb[1]*yfrac; xmax = bb[2]*xfrac; ymax = bb[3]*yfrac\n",
    "                #x = xmin/imSize[1]; y = ymin/imSize[0]; \n",
    "                #w = (xmax-xmin)/imSize[1]; h = (ymax-ymin)/imSize[0]\n",
    "                x = xmin; y = ymin\n",
    "                w = xmax-xmin; h = ymax-ymin\n",
    "                # I think we want centers?\n",
    "                x = x+w*0.5; y = y+0.5*h\n",
    "                if ll > -1:\n",
    "                    lab = LABELS[int(ll)]\n",
    "                    if lab == 'multi-figure': lab = 'figure' # rename all to figure for now\n",
    "                    try: \n",
    "                        l = labels.index(lab)\n",
    "                    except:\n",
    "                        l = -1\n",
    "                    if l > -1: # found in these labels\n",
    "                        if w<0: w=0.5\n",
    "                        if h<0: h=0.5\n",
    "                        fsave.write(str(l) + ' ' + str(max([x,0])) + ' ' + str(max([y,0])) + ' ' + str(min([w,1])) + ' ' + str(min([h,1])) + '\\n')\n",
    "                        \n",
    "            # if no boxes -- no label labels\n",
    "            if len(boxes_sq5) == 0:\n",
    "                x = 0.90; y = 0.90; w = 0.05; h=0.05\n",
    "                fsave.write(str(labels.index('no label')) + ' ' + str(max([x,0])) + ' ' + str(max([y,0])) + ' ' + str(min([w,1])) + ' ' + str(min([h,1])) + '\\n')\n",
    "\n",
    "    else:\n",
    "        print('something has gone wrong')\n",
    "        import sys; sys.exit()\n",
    "\n",
    "\n",
    "#write label file with ALL labels\n",
    "with open(storeTmps + 'annotations/'  + 'labels.txt','w') as f:\n",
    "    for l in labels:\n",
    "        f.write(l.replace(' ', '_') + '\\n')\n",
    "\n",
    "print('all done!  go classify!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232d876e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee38797b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c49f9e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebf13dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69410b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907c0157",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75b26cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34abae15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f19f8ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5280bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703c924f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cb4d06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51201f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a805af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72619c83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915223bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43abd6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
